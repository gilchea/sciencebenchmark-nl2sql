import json
import random
import numpy as np
import torch
import sqlite3
import logging
import time
import re
from contextlib import contextmanager
import sqlparse # <<< THÆ¯ VIá»†N Má»šI

import os
import shutil
import subprocess
from sqlalchemy import create_engine, text

import sqlfluff
import logging # Hoáº·c báº¥t cá»© logger nÃ o báº¡n Ä‘ang dÃ¹ng

import pandas as pd
# from sqlalchemy import create_engine, text
import numpy as np

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def set_seed(seed_value: int = 42):
    """Sets the seed for reproducibility."""
    random.seed(seed_value)
    np.random.seed(seed_value)
    torch.manual_seed(seed_value)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed_value)
    logger.info(f"Set seed to {seed_value}")

def load_json(filepath: str) -> list | dict:
    """Loads a JSON file."""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        logger.error(f"File not found: {filepath}")
        return []
    except json.JSONDecodeError:
        logger.error(f"Error decoding JSON from: {filepath}")
        return []

def save_json(data: dict | list, filepath: str):
    """Saves data to a JSON file."""
    try:
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=4)
        logger.info(f"Data saved to {filepath}")
    except IOError as e:
        logger.error(f"Error saving JSON to {filepath}: {e}")

@contextmanager
def timer(name: str):
    """A simple context manager to measure execution time."""
    start_time = time.time()
    yield
    end_time = time.time()
    logger.info(f"[{name}] executed in {end_time - start_time:.4f} seconds")

def format_schema(db_id: str, tables_data: list) -> str:
    """Formats the schema for a given db_id into a CREATE TABLE string."""
    db_schema = next((db for db in tables_data if db['db_id'] == db_id), None)

    if db_schema is None:
        return f"-- Error: Schema for db_id '{db_id}' not found."

    schema_parts = []
    col_id_to_name = {i: name[1] for i, name in enumerate(db_schema['column_names_original'])}

    for i, table_name in enumerate(db_schema['table_names_original']):
        cols = []
        table_cols = [
            (col_idx, col_name, col_type)
            for col_idx, (col_name_id, col_name) in enumerate(db_schema['column_names_original'])
            if db_schema['column_names'][col_idx][0] == i
            for col_type in [db_schema['column_types'][col_idx]]
        ]

        for col_idx, col_name, col_type in table_cols:
            original_col_name = col_id_to_name[col_idx]
            if original_col_name == '*':
                continue
            cols.append(f"  {original_col_name} {col_type.upper()}")

        pk_cols_indices = [pk_idx for pk_idx in db_schema['primary_keys'] if db_schema['column_names'][pk_idx][0] == i]
        if pk_cols_indices:
            pk_col_names = ", ".join(col_id_to_name[pk_idx] for pk_idx in pk_cols_indices)
            cols.append(f"  PRIMARY KEY ({pk_col_names})")

        table_str = f"CREATE TABLE {table_name} (\n" + ",\n".join(cols) + "\n);"
        schema_parts.append(table_str)

    fk_statements = []
    for (from_col_idx, to_col_idx) in db_schema['foreign_keys']:
        from_col_name = col_id_to_name[from_col_idx]
        from_table_idx = db_schema['column_names'][from_col_idx][0]
        from_table_name = db_schema['table_names_original'][from_table_idx]
        to_col_name = col_id_to_name[to_col_idx]
        to_table_idx = db_schema['column_names'][to_col_idx][0]
        to_table_name = db_schema['table_names_original'][to_table_idx]
        fk_statements.append(f"-- {from_table_name}.{from_col_name} TO {to_table_name}.{to_col_name}")

    if fk_statements:
        schema_parts.append("\n-- Foreign Key Relationships:\n" + "\n".join(fk_statements))

    return "\n".join(schema_parts)

def create_schema_dict(tables_data: list) -> dict:
    """Creates a dictionary mapping db_id to its formatted schema string."""
    logger.info("Creating schema string dictionary...")
    schema_dict = {}
    for db in tables_data:
        db_id = db['db_id']
        schema_dict[db_id] = format_schema(db_id, tables_data)
    logger.info(f"Processed {len(schema_dict)} schemas.")
    return schema_dict

def clean_sql_markdown(sql: str) -> str:
    """Dá»n dáº¹p markdown, lá»—i LLM, VÃ€ Dáº¤U CHáº¤M PHáº¨Y."""
    if not sql:
        return ""

    sql = str(sql).strip()

    # 1. Dá»n dáº¹p Markdown
    if sql.startswith("```sql"):
        sql = sql[6:]
    elif sql.startswith("```"):
        sql = sql[3:]
    if sql.endswith("```"):
        sql = sql[:-3]

    sql = sql.strip()

    # 2. Dá»n dáº¹p cÃ¡c lá»—i LLM
    if sql.lower().startswith("### solution:"):
        sql = sql[13:]
    if sql.lower().startswith("sql:"):
        sql = sql[4:]

    sql = sql.strip()

    # 3. Cáº¯t bá» hallucination (lá»—i báº¡n tháº¥y trong log)
    sql_parts = re.split(r'Question:', sql, maxsplit=1, flags=re.IGNORECASE)
    sql = sql_parts[0].strip()

    # 4. Chá»‰ láº¥y cÃ¢u lá»‡nh Ä‘áº§u tiÃªn vÃ  Bá»Ž Dáº¤U CHáº¤M PHáº¨Y (;)
    sql = sql.split(';')[0].strip()

    return sql

# ----- Báº®T BUá»˜C: Import lá»—i chÃ­nh xÃ¡c -----
# ChÃºng ta sáº½ tÃ¬m vÃ  import lá»—i APIParsingError má»™t cÃ¡ch an toÃ n
try:
    from sqlfluff.core.errors import APIParsingError
except ImportError:
    try:
        from sqlfluff.api import APIParsingError
    except ImportError:
        # Náº¿u phiÃªn báº£n quÃ¡ cÅ©/má»›i, ta báº¯t lá»—i chung nháº¥t
        # Máº·c dÃ¹ Ä‘iá»u nÃ y hiáº¿m khi xáº£y ra
        print("Cáº£nh bÃ¡o: KhÃ´ng tÃ¬m tháº¥y APIParsingError, sáº½ báº¯t Exception chung.")
        APIParsingError = Exception

def check_sql_syntax(sql_query: str) -> bool:
    """
    Kiá»ƒm tra xem má»™t cÃ¢u SQL cÃ³ cÃº phÃ¡p Há»¢P Lá»† hay khÃ´ng báº±ng sqlfluff.
    ÄÃ¢y lÃ  phÆ°Æ¡ng phÃ¡p xÃ¡c thá»±c (validation) Ä‘Ã¡ng tin cáº­y.
    """
    # 1. Giá»¯ láº¡i logic dá»n dáº¹p cá»§a báº¡n
    sql_query = clean_sql_markdown(sql_query)

    if not sql_query:
        return False

    try:
        # 2. YÃªu cáº§u sqlfluff phÃ¢n tÃ­ch cÃ¢u lá»‡nh
        # 'dialect="ansi"' lÃ  chuáº©n SQL chung, ráº¥t an toÃ n.
        sqlfluff.parse(sql_query, dialect="ansi")

        # 3. Náº¿u dÃ²ng trÃªn cháº¡y thÃ nh cÃ´ng (khÃ´ng vÄƒng lá»—i)
        #    cÃ³ nghÄ©a lÃ  cÃº phÃ¡p ÄÃšNG.
        return True

    except APIParsingError:
        # 4. Náº¿u sqlfluff vÄƒng lá»—i nÃ y, cÃ³ nghÄ©a lÃ 
        #    cÃº phÃ¡p 100% SAI. ÄÃ¢y lÃ  Ä‘iá»u chÃºng ta muá»‘n.
        return False

    except Exception as e:
        # 5. Báº¯t cÃ¡c lá»—i khÃ´ng mong muá»‘n khÃ¡c (lá»—i ná»™i bá»™, v.v.)
        #    Báº¡n cÃ³ thá»ƒ log lá»—i nÃ y náº¿u muá»‘n
        # logger.warning(f"Lá»—i sqlfluff khÃ´ng mong muá»‘n: {e} | SQL: {sql_query}")
        return False

# --- 1. Cáº¤U HÃŒNH ÄÆ¯á»œNG DáºªN ---
drive_folder_path = '/content/drive/MyDrive/nlp/nl2sql_project/data/cordis.sql' # Nguá»“n
local_dest_dir = '/content/cordis_full_data' # ÄÃ­ch (trÃªn Colab)

print("ðŸš€ Báº¯t Ä‘áº§u quy trÃ¬nh: Copy -> Fix Path -> Restore...")

# --- 2. COPY Dá»® LIá»†U Tá»ª DRIVE (Workaround Permission) ---
if os.path.exists(local_dest_dir):
    print(f"ðŸ—‘ï¸ XÃ³a thÆ° má»¥c cÅ© {local_dest_dir} Ä‘á»ƒ copy má»›i...")
    shutil.rmtree(local_dest_dir)

print(f"ðŸ“‚ Äang copy toÃ n bá»™ folder tá»« Drive vá» {local_dest_dir}...")
try:
    shutil.copytree(drive_folder_path, local_dest_dir)
    print("âœ… Copy thÃ nh cÃ´ng!")
except Exception as e:
    print(f"âŒ Lá»—i khi copy: {e}")
    raise e

# Cáº¥p quyá»n Ä‘á»c/ghi cho má»i user (Ä‘á»ƒ user 'postgres' Ä‘á»c Ä‘Æ°á»£c)
os.system(f"chmod -R 777 {local_dest_dir}")

# --- 3. [FIX] THAY THáº¾ $$PATH$$ TRONG FILE SQL ---
sql_file_path = os.path.join(local_dest_dir, "restore.sql")
fixed_sql_path = os.path.join(local_dest_dir, "restore_fixed_new_new.sql")

if os.path.exists(sql_file_path):
    print(f"ðŸ“ TÃ¬m tháº¥y file gá»‘c: {sql_file_path}")

    # Äá»c ná»™i dung
    with open(sql_file_path, 'r', encoding='utf-8', errors='ignore') as f:
        sql_content = f.read()

    # Thay tháº¿ $$PATH$$ báº±ng Ä‘Æ°á»ng dáº«n thá»±c táº¿ trÃªn Colab
    # LÆ°u Ã½: ÄÃ´i khi file sql ghi lÃ  '$$PATH$$/file.dat', nÃªn ta thay báº±ng local_dest_dir
    if "$$PATH$$" in sql_content:
        print("ðŸ”§ PhÃ¡t hiá»‡n placeholder '$$PATH$$', Ä‘ang thay tháº¿...")
        fixed_content = sql_content.replace("$$PATH$$", local_dest_dir)
    else:
        print("âš ï¸ KhÃ´ng tháº¥y '$$PATH$$' trong file, giá»¯ nguyÃªn ná»™i dung nhÆ°ng váº«n lÆ°u sang file má»›i.")
        fixed_content = sql_content

    # LÆ°u file Ä‘Ã£ sá»­a
    with open(fixed_sql_path, 'w', encoding='utf-8') as f:
        f.write(fixed_content)

    print(f"âœ… ÄÃ£ táº¡o file SQL Ä‘Ã£ sá»­a lá»—i Ä‘Æ°á»ng dáº«n: {fixed_sql_path}")
else:
    print(f"âŒ Lá»—i nghiÃªm trá»ng: KhÃ´ng tÃ¬m tháº¥y file {sql_file_path}")
    # Dá»«ng luÃ´n náº¿u khÃ´ng cÃ³ file sql
    raise FileNotFoundError("Missing restore.sql")

# --- 4. THá»°C THI RESTORE VÃ€O DATABASE ---
print(f"â³ Äang náº¡p dá»¯ liá»‡u tá»« {fixed_sql_path} vÃ o PostgreSQL...")

# LÆ°u Ã½: Cháº¡y lá»‡nh psql
cmd = f"sudo -u postgres psql -d cordis_temporary -f '{fixed_sql_path}'"
restore_result = subprocess.run(cmd, shell=True, capture_output=True, text=True)

if restore_result.returncode != 0:
    print("âŒ Lá»—i khi cháº¡y lá»‡nh SQL:")
    print(restore_result.stderr)
else:
    print("âœ… Lá»‡nh Restore cháº¡y xong (Kiá»ƒm tra dá»¯ liá»‡u bÃªn dÆ°á»›i).")

# # --- 5. KIá»‚M TRA Dá»® LIá»†U THá»°C Táº¾ ---
# print("\nðŸ” Äang kiá»ƒm tra sá»‘ lÆ°á»£ng báº£n ghi trong Database...")
# # Káº¿t ná»‘i DB Ä‘á»ƒ check
# db_connection_str = 'postgresql+psycopg2://postgres:password@localhost:5432/cordis_temporary?options=-c search_path=unics_cordis,public'
# engine = create_engine(db_connection_str)

# try:
#     with engine.connect() as conn:
#         # Kiá»ƒm tra báº£ng 'projects' (báº£ng trung tÃ¢m cá»§a Cordis)
#         # Náº¿u báº£ng nÃ y khÃ´ng tá»“n táº¡i nghÄ©a lÃ  lá»‡nh táº¡o báº£ng tháº¥t báº¡i
#         result = conn.execute(text("SELECT count(*) FROM projects;"))
#         count = result.scalar()
#         print(f"ðŸ“Š Sá»‘ lÆ°á»£ng dÃ²ng trong báº£ng 'projects': {count}")

#         if count > 0:
#             print("-" * 50)
#             print("ðŸŽ‰ THÃ€NH CÃ”NG Rá»°C Rá» ! DATABASE ÄÃƒ CÃ“ Dá»® LIá»†U.")
#             print("-" * 50)
#         else:
#             print("âš ï¸ Cáº¢NH BÃO: Báº£ng cÃ³ tá»“n táº¡i nhÆ°ng sá»‘ dÃ²ng = 0. Kiá»ƒm tra láº¡i ná»™i dung file .dat!")
# except Exception as e:
#     print(f"âŒ Lá»—i khi query kiá»ƒm tra: {e}")
#     print("Gá»£i Ã½: CÃ³ thá»ƒ file SQL chÆ°a táº¡o Ä‘Æ°á»£c báº£ng. Xem láº¡i log lá»—i á»Ÿ bÆ°á»›c 4.")

def check_execution_match(sql_gen: str, sql_truth: str, conn):

    if pd.isna(sql_gen) or str(sql_gen).strip() == "":
        return "Empty Generated SQL", False

    try:
        # LuÃ´n set path Ä‘á»ƒ Ä‘áº£m báº£o Ä‘Ãºng schema
        conn.execute(text("SET search_path TO unics_cordis, public;"))

        # Bá»c text() Ä‘á»ƒ fix lá»—i thÆ° viá»‡n
        t_sql_truth = text(sql_truth)
        t_sql_gen = text(sql_gen)

        df_truth = pd.read_sql(t_sql_truth, conn)
        df_gen = pd.read_sql(t_sql_gen, conn)

        if df_truth.shape != df_gen.shape:
            return "Shape Mismatch", False

        if df_truth.empty and df_gen.empty:
            return "Both Empty", True

        vals_truth = df_truth.sort_values(by=df_truth.columns.tolist()).values.tolist()
        vals_gen = df_gen.sort_values(by=df_gen.columns.tolist()).values.tolist()

        if vals_truth == vals_gen:
            return "Match", True
        else:
            return "Value Mismatch", False

    except Exception as e:
        conn.rollback() # Báº¯t buá»™c rollback
        err_msg = str(e)
        if "canceling statement due to statement timeout" in err_msg:
            # print(f"âš ï¸ DÃ²ng {index}: Timeout (>5s)")
            return "Timeout (>5s)", False
        return f"SQL Error: {err_msg.splitlines()[0]}", False
